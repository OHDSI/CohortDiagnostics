# Copyright 2020 Observational Health Data Sciences and Informatics
#
# This file is part of CohortDiagnostics
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.



#' Extract concept set sql from cohort generation SQL
#'
#' @description
#' Extracts SQL that corresponds to the conceptset (codeset) part from cohort generation SQL used 
#' to instantiated conceptSets during cohort construction.
#'
#' @param cohortSql    Complete SQL specification of cohort definition in OHDSI SQL dialect. May
#'                     contain parameters designed to be replaced by \code{SqlRender}.
#'                     The standard form SQL is generated using \code{circe-be} by
#'                     \code{WebApi} and \code{Atlas}
#' @return
#' The function will return a tibble data frame object with one row per concept id and
#'                     concept set combination in cohort definition.
#'
#' @examples
#' \dontrun{
#' conceptSetSql <- extractConceptSetsSqlFromCohortSql(cohortSql = sql)
#' }
#'
#' @export
extractConceptSetsSqlFromCohortSql <- function(cohortSql) {
  if (length(cohortSql) > 1) {
    stop("Please check if more than one cohort SQL was provided.")
  }
  sql <- gsub("with primary_events.*", "", cohortSql)
  
  # Find opening and closing parentheses:
  starts <- stringr::str_locate_all(sql, "\\(")[[1]][, 1]
  ends <- stringr::str_locate_all(sql, "\\)")[[1]][, 1]
  
  x <- rep(0, nchar(sql))
  x[starts] <- 1
  x[ends] <- -1
  level <- cumsum(x)
  level0 <- which(level == 0)
  
  subQueryLocations <-
    stringr::str_locate_all(sql, "SELECT [0-9]+ as codeset_id")[[1]]
  subQueryCount <- nrow(subQueryLocations)
  conceptsetSqls <- vector("character", subQueryCount)
  conceptSetIds <- vector("integer", subQueryCount)
  
  temp <- list()
  if (subQueryCount > 0) {
    for (i in 1:subQueryCount) {
      startForSubQuery <- min(starts[starts > subQueryLocations[i, 2]])
      endForSubQuery <- min(level0[level0 > startForSubQuery])
      subQuery <-
        paste(stringr::str_sub(sql, subQueryLocations[i, 1], endForSubQuery),
              "C")
      conceptsetSqls[i] <- subQuery
      conceptSetIds[i] <- stringr::str_replace(
        subQuery,
        pattern = stringr::regex(
          pattern = "SELECT ([0-9]+) as codeset_id.*",
          ignore_case = TRUE,
          multiline = TRUE,
          dotall = TRUE
        ),
        replacement = "\\1"
      ) %>%
        utils::type.convert()
      temp[[i]] <- tidyr::tibble(conceptSetId = conceptSetIds[i],
                                 conceptSetSql = conceptsetSqls[i])
    }
  } else {
    temp <- tidyr::tibble()
  }
  return(dplyr::bind_rows(temp))
}


#' Extract concept set json from cohort json
#'
#' @description
#' Extracts json that corresponds to the conceptset definition in a cohort json definition
#'
#' @param cohortJson   Complete JSON specification of cohort definition. The standard form
#'                     is generated by \code{WebApi}
#' @return
#' The function will return a tibble data frame object with one row per
#' conceptSet id in cohort definition.
#'
#' @examples
#' \dontrun{
#' conceptSetsJson <- extractConceptSetsJsonFromCohortJson(cohortJson = json)
#' }
#'
#' @export
extractConceptSetsJsonFromCohortJson <- function(cohortJson) {
  cohortDefinition <- RJSONIO::fromJSON(content = cohortJson, digits = 23)
  if ("expression" %in% names(cohortDefinition)) {
    expression <- cohortDefinition$expression
  } else {
    expression <- cohortDefinition
  }
  conceptSetExpression <- list()
  if (length(expression$ConceptSets) > 0) {
    for (i in (1:length(expression$ConceptSets))) {
      conceptSetExpression[[i]] <-
        tidyr::tibble(
          conceptSetId = expression$ConceptSets[[i]]$id,
          conceptSetName = expression$ConceptSets[[i]]$name,
          conceptSetExpression = expression$ConceptSets[[i]]$expression$items %>% RJSONIO::toJSON(digits = 23)
        )
    }
  } else {
    conceptSetExpression <- tidyr::tibble()
  }
  return(dplyr::bind_rows(conceptSetExpression))
}



# private function of cohort diagnostics package
combineConceptSetsFromCohorts <- function(cohorts) {
  #cohorts should be a dataframe with atleast cohortId, sql and json
  
  errorMessage <- checkmate::makeAssertCollection()
  checkmate::assertDataFrame(
    x = cohorts,
    min.cols = 4,
    add = errorMessage
  )
  checkmate::assertNames(
    x = colnames(cohorts),
    must.include = c('cohortId', 'sql', 'json', 'cohortName')
  )
  checkmate::reportAssertions(errorMessage)
  
  checkmate::assertDataFrame(
    x = cohorts %>% dplyr::select(.data$cohortId, .data$sql, .data$json, .data$cohortName),
    any.missing = FALSE,
    min.cols = 4,
    add = errorMessage
  )
  checkmate::reportAssertions(errorMessage)
  
  conceptSets <- list()
  conceptSetCounter <- 0
  
  for (i in (1:nrow(cohorts))) {
    cohort <- cohorts[i,]
    sql <- extractConceptSetsSqlFromCohortSql(cohortSql = cohort$sql)
    json <- extractConceptSetsJsonFromCohortJson(cohortJson = cohort$json)
    
    if (nrow(sql) == 0 || nrow(json) == 0) {
      ParallelLogger::logInfo(
        "Cohort Definition expression does not have a concept set expression\n",
        "    Skipping Cohort: ", 
        cohort$cohortName
      )
    } else {
      if (!length(sql$conceptSetId %>% unique()) == length(json$conceptSetId %>% unique())) {
        stop(
          "Mismatch in concept set IDs between SQL and JSON for cohort ",
          cohort$cohortFullName
        )
      }
      if (length(sql) > 0 && length(json) > 0) {
        conceptSetCounter <- conceptSetCounter + 1
        conceptSets[[conceptSetCounter]] <-
          tidyr::tibble(cohortId = cohort$cohortId,
                        dplyr::inner_join(x = sql, y = json, by = "conceptSetId"))
      }
    }
  }
  conceptSets <- dplyr::bind_rows(conceptSets) %>%
    dplyr::arrange(.data$cohortId, .data$conceptSetId)
  
  uniqueConceptSets <- conceptSets %>%
    dplyr::select(.data$conceptSetExpression) %>%
    dplyr::distinct() %>%
    dplyr::mutate(uniqueConceptSetId = dplyr::row_number())
  
  conceptSets <- conceptSets %>%
    dplyr::inner_join(uniqueConceptSets) %>% 
    dplyr::distinct() %>% 
    dplyr::relocate(.data$uniqueConceptSetId, .data$cohortId, .data$conceptSetId) %>% 
    dplyr::arrange(.data$uniqueConceptSetId, .data$cohortId, .data$conceptSetId)
  
  return(conceptSets)
}


mergeTempTables <- function(connection, tableName, tempTables, oracleTempSchema) {
  valueString <- paste(tempTables, collapse = "\n\n  UNION ALL\n\n  SELECT *\n  FROM ")
  sql <- sprintf("SELECT *\nINTO %s\nFROM (\n  SELECT *\n  FROM %s\n) tmp;", tableName, valueString)
  sql <- SqlRender::translate(sql, targetDialect = connection@dbms, oracleTempSchema = oracleTempSchema)
  DatabaseConnector::executeSql(connection, sql, progressBar = FALSE, reportOverallTime = FALSE)
  
  # Drop temp tables:
  for (tempTable in tempTables) {
    sql <- sprintf("TRUNCATE TABLE %s;\nDROP TABLE %s;", tempTable, tempTable)
    sql <- SqlRender::translate(sql, targetDialect = connection@dbms, oracleTempSchema = oracleTempSchema)
    DatabaseConnector::executeSql(connection, sql, progressBar = FALSE, reportOverallTime = FALSE)
  }
}


#private function of cohort diagnostics to instantiate concept sets for a cohort
instantiateUniqueConceptSets <- function(uniqueConceptSets,
                                         connection,
                                         cdmDatabaseSchema,
                                         oracleTempSchema,
                                         instantiatedCodeSets = '#InstConceptSets') {
  ParallelLogger::logInfo("  Instantiating concept sets")
  sql <- sapply(split(uniqueConceptSets, 1:nrow(uniqueConceptSets)),
                function(x) {
                  sub(
                    "SELECT [0-9]+ as codeset_id",
                    sprintf("SELECT %s as codeset_id", x$uniqueConceptSetId),
                    x$conceptSetSql
                  )
                })
  
  batchSize <- 100
  tempTables <- c()
  pb <- utils::txtProgressBar(style = 3)
  for (start in seq(1, length(sql), by = batchSize)) {
    utils::setTxtProgressBar(pb, start/length(sql))
    tempTable <- paste("#", paste(sample(letters, 20, replace = TRUE), collapse = ""), sep = "")
    tempTables <- c(tempTables, tempTable)
    end <- min(start + batchSize - 1, length(sql))
    sqlSubset <- sql[start:end]
    sqlSubset <- paste(sqlSubset, collapse = "\n\n  UNION ALL\n\n")
    sqlSubset <- sprintf("SELECT *\nINTO %s\nFROM (\n %s\n) tmp;", tempTable, sqlSubset)
    sqlSubset <- SqlRender::render(sqlSubset, vocabulary_database_schema = cdmDatabaseSchema)
    sqlSubset <- SqlRender::translate(sqlSubset,
                                      targetDialect = connection@dbms,
                                      oracleTempSchema = oracleTempSchema)
    DatabaseConnector::executeSql(connection, sqlSubset, progressBar = FALSE, reportOverallTime = FALSE)
  }
  utils::setTxtProgressBar(pb, 1)
  close(pb)
  
  mergeTempTables(connection = connection,
                  tableName = instantiatedCodeSets,
                  tempTables = tempTables, 
                  oracleTempSchema = oracleTempSchema)
}

runConceptSetDiagnostics <- function(connection,
                                     oracleTempSchema,
                                     cdmDatabaseSchema,
                                     databaseId,
                                     cohorts,
                                     runIncludedSourceConcepts,
                                     runResolveCohortConceptSetsToConceptIds = TRUE,
                                     runOrphanConcepts,
                                     exportFolder,
                                     minCellCount,
                                     includeSourceConceptTable = '#inc_src_con',
                                     orphan_concept = '#orphan_concept',
                                     conceptCountsDatabaseSchema = cdmDatabaseSchema,
                                     conceptCountsTable = "concept_counts",
                                     exportConceptCountTableForDatabase = FALSE,
                                     conceptCountsTableIsTemp = FALSE,
                                     useExternalConceptCountsTable = FALSE,
                                     incremental = FALSE,
                                     uniqueConceptIdTable = NULL,
                                     recordKeepingFile) {
  
  startConceptSetDiagnostics <- Sys.time()
  ParallelLogger::logInfo("Starting concept set diagnostics at ", Sys.time())
  
  subset <- tibble::tibble()
  if (runIncludedSourceConcepts) {
    subsetIncluded <- subsetToRequiredCohorts(
      cohorts = cohorts,
      task = "runIncludedSourceConcepts",
      incremental = incremental,
      recordKeepingFile = recordKeepingFile
    )
    subset <- dplyr::bind_rows(subset, subsetIncluded)
  }
  if (runOrphanConcepts) {
    subsetOrphans <- subsetToRequiredCohorts(
      cohorts = cohorts,
      task = "runOrphanConcepts",
      incremental = incremental,
      recordKeepingFile = recordKeepingFile
    )
    subset <- dplyr::bind_rows(subset, subsetOrphans)
  }
  subset <- dplyr::distinct(subset)
  
  if (nrow(subset) == 0) {
    return()
  }
  
  conceptSets <- combineConceptSetsFromCohorts(subset)
  
  uniqueConceptSets <- conceptSets %>%
    dplyr::select(-.data$cohortId, -.data$conceptSetId) %>% 
    dplyr::group_by(.data$uniqueConceptSetId) %>%
    dplyr::slice(1)
  
  ParallelLogger::logInfo("  Uploading unique concept sets to server. Number of records: ",
                          scales::comma(nrow(uniqueConceptSets)), 
                          ". This may take some time depending on size.")
  DatabaseConnector::insertTable(connection = connection,
                                 tableName = '#unique_concept_sets',
                                 data = uniqueConceptSets, 
                                 dropTableIfExists = TRUE,
                                 createTable = TRUE,
                                 tempTable = TRUE,
                                 progressBar = TRUE,
                                 camelCaseToSnakeCase = TRUE)
  DatabaseConnector::insertTable(connection = connection,
                                 tableName = '#concept_sets',
                                 data = conceptSets %>% 
                                   dplyr::select(.data$uniqueConceptSetId, 
                                                 .data$cohortId, 
                                                 .data$conceptSetId) %>% 
                                   dplyr::distinct(), 
                                 dropTableIfExists = TRUE,
                                 createTable = TRUE,
                                 tempTable = TRUE,
                                 progressBar = TRUE,
                                 camelCaseToSnakeCase = TRUE)
  ParallelLogger::logInfo("    Done.")
  # there is now a temp table called #unique_concept_sets
  
  instantiateUniqueConceptSets(
    uniqueConceptSets = uniqueConceptSets,
    connection = connection,
    cdmDatabaseSchema = cdmDatabaseSchema,
    oracleTempSchema = oracleTempSchema,
    instantiatedCodeSets = '#InstConceptSets'
  )
  # there is now a temp table called #InstConceptSets
  sql <- "SELECT DISTINCT concept_sets.cohort_id,
              concept_sets.concept_set_id,
              inst.concept_id
          FROM #concept_sets concept_sets
          INNER JOIN @instantiated_code_sets inst
          ON concept_sets.unique_concept_set_id = inst.codeset_id"
  conceptSetConceptIds <- DatabaseConnector::renderTranslateQuerySql(connection = connection,
                                                                     sql = sql,
                                                                     instantiated_code_sets = '#InstConceptSets') %>% 
    tidyr::tibble()
  writeToCsv(data = conceptSetConceptIds, 
             fileName = file.path(exportFolder, "concept_sets_concept_id.csv"), 
             incremental = incremental)
  
  writeToCsv(data = conceptSets %>% 
               dplyr::select(-.data$uniqueConceptSetId), 
             fileName = file.path(exportFolder, "concept_sets.csv"), 
             incremental = incremental)
  
  data <- createConceptCountsTable(
    connection = connection,
    cdmDatabaseSchema = cdmDatabaseSchema,
    oracleTempSchema = oracleTempSchema,
    conceptCountsDatabaseSchema = conceptCountsDatabaseSchema,
    conceptCountsTable = conceptCountsTable,
    conceptCountsTableIsTemp = conceptCountsTableIsTemp,
    getConceptCountsTableAsDataFrame = TRUE
  )
  if (exportConceptCountTableForDatabase) {
    conceptCountTableForDatabase <- data %>% 
      dplyr::mutate(databaseId = !!databaseId) %>% 
      dplyr::relocate(.data$databaseId)
    if (nrow(conceptCountTableForDatabase) > 0) {
      conceptCountTableForDatabase <- enforceMinCellValue(conceptCountTableForDatabase, "conceptCount", minCellCount)
      conceptCountTableForDatabase <- enforceMinCellValue(conceptCountTableForDatabase, "conceptSubjects", minCellCount)
    }
    writeToCsv(data = conceptCountTableForDatabase, 
               fileName = file.path(exportFolder, "database_concept_count.csv")
    )
  }
  
  # if (!is.null(uniqueConceptIdTable)) {
  #   if (is.null(conceptCountsDatabaseSchema) &&
  #       isTRUE(conceptCountsTableIsTemp)
  #   ) {
  #     conceptCountsTableFullName <- conceptCountsTable
  #   } else {
  #     conceptCountsTableFullName <- paste0(conceptCountsDatabaseSchema, '.', conceptCountsTable)
  #   }
  # }
  
  if (runIncludedSourceConcepts) {
    # Included concepts ------------------------------------------------------------------
    ParallelLogger::logInfo("  Fetching included source concepts - Started at ", Sys.time())
    if (nrow(subsetIncluded) > 0) {
      start <- Sys.time()
      ParallelLogger::logInfo("  Counting codes in concept sets")
      if (useExternalConceptCountsTable) {
        ParallelLogger::logWarn("  Use of external concept count table is not supported")
        stop()
        # sql <-
        #   SqlRender::loadRenderTranslateSql(
        #     "CohortSourceConceptsFromCcTable.sql",
        #     packageName = "CohortDiagnostics",
        #     dbms = connection@dbms,
        #     oracleTempSchema = oracleTempSchema,
        #     cdm_database_schema = cdmDatabaseSchema,
        #     concept_counts_database_schema = conceptCountsDatabaseSchema,
        #     concept_counts_table = conceptCountsTable,
        #     concept_counts_table_is_temp = conceptCountsTableIsTemp
        #   )
        # 
        # sourceCounts <-
        #   DatabaseConnector::querySql(connection, sql, snakeCaseToCamelCase = TRUE)
        # 
        # sql <-
        #   SqlRender::loadRenderTranslateSql(
        #     "CohortStandardConceptsFromCcTable.sql",
        #     packageName = "CohortDiagnostics",
        #     dbms = connection@dbms,
        #     oracleTempSchema = oracleTempSchema,
        #     cdm_database_schema = cdmDatabaseSchema,
        #     concept_counts_database_schema = conceptCountsDatabaseSchema,
        #     concept_counts_table = conceptCountsTable,
        #     concept_counts_table_is_temp = conceptCountsTableIsTemp
        #   )
        # standardCounts <-
        #   DatabaseConnector::querySql(connection, sql, snakeCaseToCamelCase = TRUE)
        # 
        # # To avoid double counting, subtract standard concept counts included in source counts.
        # # Note: this can create negative counts, because a source concept can be double counted itself
        # # if it maps to more than one standard concept, but it will show correctly in the viewer app,
        # # where the counts will be added back in.
        # dupCounts <-
        #   aggregate(conceptCount ~ conceptId, sourceCounts, sum)
        # colnames(dupCounts)[2] <- "dupCount"
        # dupSubjects <-
        #   aggregate(conceptSubjects ~ conceptId, sourceCounts, sum)
        # colnames(dupSubjects)[2] <- "dupSubjects"
        # standardCounts <-
        #   merge(standardCounts, dupCounts, all.x = TRUE)
        # standardCounts <-
        #   merge(standardCounts, dupSubjects, all.x = TRUE)
        # standardCounts$dupCount[is.na(standardCounts$dupCount)] <- 0
        # standardCounts$dupSubjects[is.na(standardCounts$dupSubjects)] <-
        #   0
        # standardCounts$conceptCount <-
        #   standardCounts$conceptCount - standardCounts$dupCount
        # standardCounts$conceptSubjects <-
        #   standardCounts$conceptSubjects - standardCounts$dupSubjects
        # standardCounts$dupCount <- NULL
        # standardCounts$dupSubjects <- NULL
        # 
        # counts <- dplyr::bind_rows(sourceCounts, standardCounts)
      } else {
        sql <- SqlRender::loadRenderTranslateSql(
          "CohortSourceCodes.sql",
          packageName = "CohortDiagnostics",
          dbms = connection@dbms,
          oracleTempSchema = oracleTempSchema,
          cdm_database_schema = cdmDatabaseSchema,
          instantiated_concept_sets = '#InstConceptSets',
          include_source_concept_table = includeSourceConceptTable,
          by_month = FALSE
        )
        DatabaseConnector::executeSql(connection = connection,
                                      sql = sql)
        counts <- DatabaseConnector::renderTranslateQuerySql(connection = connection, 
                                                             sql = "select * from @include_source_concept_table",
                                                             include_source_concept_table = includeSourceConceptTable,
                                                             snakeCaseToCamelCase = TRUE) %>% 
          tidyr::tibble() %>% 
          dplyr::rename(uniqueConceptSetId = .data$conceptSetId) %>% 
          dplyr::inner_join(conceptSets %>% dplyr::select(.data$uniqueConceptSetId, .data$cohortId, .data$conceptSetId)) %>% 
          dplyr::select(-.data$uniqueConceptSetId) %>% 
          dplyr::mutate(databaseId = !!databaseId) %>% 
          dplyr::relocate(.data$databaseId, .data$cohortId, 
                          .data$conceptSetId, .data$conceptId) %>% 
          dplyr::distinct()
        
        if (nrow(counts) > 0) {
          counts$databaseId <- databaseId
          counts <- enforceMinCellValue(counts, "conceptSubjects", minCellCount)
          counts <- enforceMinCellValue(counts, "conceptCount", minCellCount)
        }
        writeToCsv(
          counts,
          file.path(exportFolder, "included_source_concept.csv"),
          incremental = incremental,
          cohortId = subsetIncluded$cohortId
        )
        recordTasksDone(
          cohortId = subsetIncluded$cohortId,
          task = "runIncludedSourceConcepts",
          checksum = subsetIncluded$checksum,
          recordKeepingFile = recordKeepingFile,
          incremental = incremental
        )
        delta <- Sys.time() - start
        ParallelLogger::logInfo(paste(
          "  Finding source codes took",
          signif(delta, 3),
          attr(delta, "units")
        ))
      }
    }
  }
  
  if (runOrphanConcepts) {
    # Orphan concepts ---------------------------------------------------------
    ParallelLogger::logInfo("  Finding orphan concepts - started at ", Sys.time())
    if (nrow(subsetOrphans > 0)) {
      start <- Sys.time()
      if (!useExternalConceptCountsTable) {
        ParallelLogger::logInfo("  Using internal concept count table.")
      } else {
        ParallelLogger::logWarn("  Use of external concept count table is not supported")
        stop()
      }
      
      # [OPTIMIZATION idea] can we modify the sql to do this for all uniqueConceptSetId in one query using group by?
      data <- list()
      for (i in (1:nrow(uniqueConceptSets))) {
        conceptSet <- uniqueConceptSets[i,]
        cohort <- cohorts %>% 
          dplyr::inner_join(conceptSets %>% 
                              dplyr::inner_join(conceptSet) %>% 
                              dplyr::select(.data$cohortId) %>% 
                              dplyr::distinct())
        ParallelLogger::logInfo("  Finding orphan concepts for concept set ",
                                conceptSet$conceptSetName, 
                                "found in cohorts :\n    ",
                                paste0(cohort %>% 
                                         dplyr::pull(.data$cohortName) %>% 
                                         paste0(collapse = "/n    ")))
        data[[i]] <-
          .findOrphanConcepts(
            connection = connection,
            cdmDatabaseSchema = cdmDatabaseSchema,
            oracleTempSchema = oracleTempSchema,
            useCodesetTable = TRUE,
            codesetId = conceptSet$uniqueConceptSetId,
            conceptCountsDatabaseSchema = conceptCountsDatabaseSchema,
            conceptCountsTable = conceptCountsTable,
            conceptCountsTableIsTemp = conceptCountsTableIsTemp,
            instantiatedCodeSets = '#InstConceptSets',
            orphanConceptTable = '#recommended_concepts'
          )
        
        if (!is.null(databaseId) && !is.null(uniqueConceptIdTable)) {
          sql <- "DELETE FROM @cohort_database_schema.@unique_concept_id_table
                  WHERE database_id = '@database_id'
                  AND cohort_id in (@cohort_ids)
                  AND task = '@task';
      
                  INSERT INTO @cohort_database_schema.@unique_concept_id_table
                  (database_id, cohort_id, task, concept_id)
                  SELECT DISTINCT '@database_id' as database_id,
                         conc.cohort_id,
                         '@task' as task,
                         orphan.concept_id
                  FROM @orphan_concept_table orphan
                  INNER JOIN #unique_concept_sets unq
                  ON orphan.codeset_id = unq.unique_concept_set_id
                  INNER JOIN #concept_sets conc
                  ON orphan.codeset_id = conc.unique_concept_set_id;"
            DatabaseConnector::renderTranslateExecuteSql(connection = connection,
                                                         sql = sql,
                                                         cohort_database_schema = cohortDatabaseSchema,
                                                         unique_concept_id_table = uniqueConceptIdTable,
                                                         database_id = databaseId,
                                                         cohort_ids = paste0(cohort$cohortId %>% unique(), collapse = ","),
                                                         orphan_concept_table = '#recommended_concepts',
                                                         task = 'runOrphanConcepts')
        }
      }
      data <- dplyr::bind_rows(data) %>% 
        dplyr::distinct() %>% 
        dplyr::rename(uniqueConceptSetId = .data$codesetId) %>% 
        dplyr::inner_join(conceptSets %>% 
                            dplyr::select(.data$uniqueConceptSetId, 
                                          .data$cohortId, 
                                          .data$conceptSetId)) %>% 
        dplyr::select(-.data$uniqueConceptSetId) %>% 
        dplyr::mutate(databaseId = !!databaseId) %>% 
        dplyr::relocate(.data$cohortId, .data$conceptSetId, .data$databaseId)
      
      # ParallelLogger::logInfo("  Uploading to orphan_concept concept_id temporary table. This may take some time. Number of rows: ", 
      #                         scales::comma(data %>% dplyr::select(.data$conceptId) %>% dplyr::distinct() %>% nrow()))
      # DatabaseConnector::insertTable(connection = connection, 
      #                                tableName = '#orphan_concept',
      #                                data = data %>% dplyr::select(.data$conceptId) %>% dplyr::distinct(),
      #                                dropTableIfExists = TRUE,
      #                                createTable = TRUE,
      #                                tempTable = TRUE,
      #                                progressBar = TRUE,
      #                                camelCaseToSnakeCase = TRUE)
      
      if (nrow(data) > 0) {
        data <- enforceMinCellValue(data, "conceptCount", minCellCount)
        data <- enforceMinCellValue(data, "conceptSubjects", minCellCount)
      }
      
      writeToCsv(
        data,
        file.path(exportFolder, "orphan_concept.csv"),
        incremental = incremental,
        cohortId = subsetOrphans$cohortId
      )
      
      recordTasksDone(
        cohortId = subsetOrphans$cohortId,
        task = "runOrphanConcepts",
        checksum = subsetOrphans$checksum,
        recordKeepingFile = recordKeepingFile,
        incremental = incremental
      )
      
      # if (!useExternalConceptCountsTable) {
      #   ParallelLogger::logTrace("Dropping temp concept counts")
      #   sql <- "TRUNCATE TABLE #concept_counts; DROP TABLE #concept_counts;"
      #   DatabaseConnector::renderTranslateExecuteSql(connection,
      #                                                sql,
      #                                                progressBar = FALSE,
      #                                                reportOverallTime = FALSE)
      # }
      delta <- Sys.time() - start
      ParallelLogger::logInfo(paste(
        "Finding orphan concepts took",
        signif(delta, 3),
        attr(delta, "units")
      ))
    }
  }
  ParallelLogger::logTrace("Dropping temp concept set tables")
  sql <- "TRUNCATE TABLE #InstConceptSets; DROP TABLE #InstConceptSets;"
  DatabaseConnector::renderTranslateExecuteSql(
    connection,
    sql,
    oracleTempSchema = oracleTempSchema,
    progressBar = FALSE,
    reportOverallTime = FALSE
  )
  
  delta <- Sys.time() - startConceptSetDiagnostics
  ParallelLogger::logInfo(paste(
    "Running concept set diagnostics",
    signif(delta, 3),
    attr(delta, "units")
  ))
}
