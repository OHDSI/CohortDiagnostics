# Copyright 2020 Observational Health Data Sciences and Informatics
#
# This file is part of CohortDiagnostics
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.



#' Extract concept set sql from cohort generation SQL
#'
#' @description
#' Extracts SQL that corresponds to the conceptset (codeset) part from cohort generation SQL used 
#' to instantiated conceptSets during cohort construction.
#'
#' @param cohortSql    Complete SQL specification of cohort definition in OHDSI SQL dialect. May
#'                     contain parameters designed to be replaced by \code{SqlRender}.
#'                     The standard form SQL is generated using \code{circe-be} by
#'                     \code{WebApi} and \code{Atlas}
#' @return
#' The function will return a tibble data frame object with one row per concept id and
#'                     concept set combination in cohort definition.
#'
#' @examples
#' \dontrun{
#' conceptSetSql <- extractConceptSetsSqlFromCohortSql(cohortSql = sql)
#' }
#'
#' @export
extractConceptSetsSqlFromCohortSql <- function(cohortSql) {
  if (length(cohortSql) > 1) {
    stop("Please check if more than one cohort SQL was provided.")
  }
  sql <- gsub("with primary_events.*", "", cohortSql)
  
  # Find opening and closing parentheses:
  starts <- stringr::str_locate_all(sql, "\\(")[[1]][, 1]
  ends <- stringr::str_locate_all(sql, "\\)")[[1]][, 1]
  
  x <- rep(0, nchar(sql))
  x[starts] <- 1
  x[ends] <- -1
  level <- cumsum(x)
  level0 <- which(level == 0)
  
  subQueryLocations <-
    stringr::str_locate_all(sql, "SELECT [0-9]+ as codeset_id")[[1]]
  subQueryCount <- nrow(subQueryLocations)
  conceptsetSqls <- vector("character", subQueryCount)
  conceptSetIds <- vector("integer", subQueryCount)
  
  temp <- list()
  if (subQueryCount > 0) {
    for (i in 1:subQueryCount) {
      startForSubQuery <- min(starts[starts > subQueryLocations[i, 2]])
      endForSubQuery <- min(level0[level0 > startForSubQuery])
      subQuery <-
        paste(stringr::str_sub(sql, subQueryLocations[i, 1], endForSubQuery),
              "C")
      conceptsetSqls[i] <- subQuery
      conceptSetIds[i] <- stringr::str_replace(
        subQuery,
        pattern = stringr::regex(
          pattern = "SELECT ([0-9]+) as codeset_id.*",
          ignore_case = TRUE,
          multiline = TRUE,
          dotall = TRUE
        ),
        replacement = "\\1"
      ) %>%
        utils::type.convert()
      temp[[i]] <- tidyr::tibble(conceptSetId = conceptSetIds[i],
                                 conceptSetSql = conceptsetSqls[i])
    }
  } else {
    temp <- tidyr::tibble()
  }
  return(dplyr::bind_rows(temp))
}


#' Extract concept set json from cohort json
#'
#' @description
#' Extracts json that corresponds to the conceptset definition in a cohort json definition
#'
#' @param cohortJson   Complete JSON specification of cohort definition. The standard form
#'                     is generated by \code{WebApi}
#' @return
#' The function will return a tibble data frame object with one row per
#' conceptSet id in cohort definition.
#'
#' @examples
#' \dontrun{
#' conceptSetsJson <- extractConceptSetsJsonFromCohortJson(cohortJson = json)
#' }
#'
#' @export
extractConceptSetsJsonFromCohortJson <- function(cohortJson) {
  cohortDefinition <- RJSONIO::fromJSON(content = cohortJson, digits = 23)
  if ("expression" %in% names(cohortDefinition)) {
    expression <- cohortDefinition$expression
  } else {
    expression <- cohortDefinition
  }
  conceptSetExpression <- list()
  if (length(expression$ConceptSets) > 0) {
    for (i in (1:length(expression$ConceptSets))) {
      conceptSetExpression[[i]] <-
        tidyr::tibble(
          conceptSetId = expression$ConceptSets[[i]]$id,
          conceptSetName = expression$ConceptSets[[i]]$name,
          conceptSetExpression = expression$ConceptSets[[i]]$expression$items %>% RJSONIO::toJSON(digits = 23)
        )
    }
  } else {
    conceptSetExpression <- tidyr::tibble()
  }
  return(dplyr::bind_rows(conceptSetExpression))
}



# private function of cohort diagnostics package
combineConceptSetsFromCohorts <- function(cohorts) {
  #cohorts should be a dataframe with atleast cohortId, sql and json
  
  errorMessage <- checkmate::makeAssertCollection()
  checkmate::assertDataFrame(
    x = cohorts,
    any.missing = FALSE,
    min.cols = 3,
    add = errorMessage
  )
  checkmate::assertNames(
    x = colnames(cohorts),
    must.include = c('cohortId', 'sql', 'json', 'cohortFullName')
  )
  checkmate::reportAssertions(errorMessage)
  
  conceptSets <- list()
  conceptSetCounter <- 0
  
  for (i in (1:nrow(cohorts))) {
    cohort <- cohorts %>%
      dplyr::slice(i)
    sql <-
      extractConceptSetsSqlFromCohortSql(cohortSql = cohort$sql)
    json <-
      extractConceptSetsJsonFromCohortJson(cohortJson = cohort$json)
    
    if (!length(sql$conceptSetId %>% unique()) == length(json$conceptSetId %>% unique())) {
      stop(
        "Mismatch in concept set IDs between SQL and JSON for cohort ",
        cohort$cohortFullName
      )
    }
    if (length(sql) > 0 && length(json) > 0) {
      conceptSetCounter <- conceptSetCounter + 1
      conceptSets[[conceptSetCounter]] <-
        tidyr::tibble(cohortId = cohort$cohortId,
                      dplyr::inner_join(x = sql, y = json, by = "conceptSetId"))
    }
  }
  conceptSets <- dplyr::bind_rows(conceptSets) %>%
    dplyr::arrange("cohortId", "conceptSetId")
  
  uniqueConceptSets <- conceptSets %>%
    dplyr::select(.data$conceptSetExpression) %>%
    dplyr::distinct() %>%
    dplyr::mutate(uniqueConceptSetId = dplyr::row_number())
  
  conceptSets <- conceptSets %>%
    dplyr::inner_join(uniqueConceptSets, by = "conceptSetExpression")
  
  return(conceptSets)
}


mergeTempTables <- function(connection, tableName, tempTables, oracleTempSchema) {
  valueString <- paste(tempTables, collapse = "\n\n  UNION ALL\n\n  SELECT *\n  FROM ")
  sql <- sprintf("SELECT *\nINTO %s\nFROM (\n  SELECT *\n  FROM %s\n) tmp;", tableName, valueString)
  sql <- SqlRender::translate(sql, targetDialect = connection@dbms, oracleTempSchema = oracleTempSchema)
  DatabaseConnector::executeSql(connection, sql, progressBar = FALSE, reportOverallTime = FALSE)
  
  # Drop temp tables:
  for (tempTable in tempTables) {
    sql <- sprintf("TRUNCATE TABLE %s;\nDROP TABLE %s;", tempTable, tempTable)
    sql <- SqlRender::translate(sql, targetDialect = connection@dbms, oracleTempSchema = oracleTempSchema)
    DatabaseConnector::executeSql(connection, sql, progressBar = FALSE, reportOverallTime = FALSE)
  }
}


#private function of cohort diagnostics to instantiate concept sets for a cohort
instantiateUniqueConceptSets <- function(uniqueConceptSets,
                                         connection,
                                         cdmDatabaseSchema,
                                         oracleTempSchema) {
  ParallelLogger::logInfo("Instantiating concept sets")
  sql <- sapply(split(uniqueConceptSets, 1:nrow(uniqueConceptSets)),
                function(x) {
                  sub(
                    "SELECT [0-9]+ as codeset_id",
                    sprintf("SELECT %s as codeset_id", x$uniqueConceptSetId),
                    x$conceptSetSql
                  )
                })
  
  batchSize <- 100
  tempTables <- c()
  pb <- utils::txtProgressBar(style = 3)
  for (start in seq(1, length(sql), by = batchSize)) {
    utils::setTxtProgressBar(pb, start/length(sql))
    tempTable <- paste("#", paste(sample(letters, 20, replace = TRUE), collapse = ""), sep = "")
    tempTables <- c(tempTables, tempTable)
    end <- min(start + batchSize - 1, length(sql))
    sqlSubset <- sql[start:end]
    sqlSubset <- paste(sqlSubset, collapse = "\n\n  UNION ALL\n\n")
    sqlSubset <- sprintf("SELECT *\nINTO %s\nFROM (\n %s\n) tmp;", tempTable, sqlSubset)
    sqlSubset <- SqlRender::render(sqlSubset, vocabulary_database_schema = cdmDatabaseSchema)
    sqlSubset <- SqlRender::translate(sqlSubset,
                                      targetDialect = connection@dbms,
                                      oracleTempSchema = oracleTempSchema)
    DatabaseConnector::executeSql(connection, sqlSubset, progressBar = FALSE, reportOverallTime = FALSE)
  }
  utils::setTxtProgressBar(pb, 1)
  close(pb)
  
  mergeTempTables(connection = connection,
                  tableName = "#Codesets",
                  tempTables = tempTables, 
                  oracleTempSchema = oracleTempSchema)
}

runConceptSetDiagnostics <- function(connection,
                                     oracleTempSchema,
                                     cdmDatabaseSchema,
                                     databaseId,
                                     cohorts,
                                     runIncludedSourceConcepts,
                                     runOrphanConcepts,
                                     exportFolder,
                                     minCellCount,
                                     conceptCountsDatabaseSchema = cdmDatabaseSchema,
                                     conceptCountsTable = "concept_counts",
                                     conceptCountsTableIsTemp = FALSE,
                                     useExternalConceptCountsTable = FALSE,
                                     incremental = FALSE,
                                     recordKeepingFile) {
  startConceptSetDiagnostics <- Sys.time()
  ParallelLogger::logInfo("Starting concept set diagnostics at ", Sys.time())
  
  subset <- tibble::tibble()
  if (runIncludedSourceConcepts) {
    subsetIncluded <- subsetToRequiredCohorts(
      cohorts = cohorts,
      task = "runIncludedSourceConcepts",
      incremental = incremental,
      recordKeepingFile = recordKeepingFile
    )
    subset <- dplyr::bind_rows(subset, subsetIncluded)
  }
  if (runOrphanConcepts) {
    subsetOrphans <- subsetToRequiredCohorts(
      cohorts = cohorts,
      task = "runOrphanConcepts",
      incremental = incremental,
      recordKeepingFile = recordKeepingFile
    )
    subset <- dplyr::bind_rows(subset, subsetOrphans)
  }
  subset <- dplyr::distinct(subset)
  
  if (nrow(subset) == 0) {
    return()
  }
  
  conceptSets <- combineConceptSetsFromCohorts(subset)
  uniqueConceptSets <- conceptSets %>%
    dplyr::group_by(.data$uniqueConceptSetId) %>%
    dplyr::slice(1)
  
  instantiateUniqueConceptSets(
    uniqueConceptSets = uniqueConceptSets,
    connection = connection,
    cdmDatabaseSchema = cdmDatabaseSchema,
    oracleTempSchema = oracleTempSchema
  )
  
  if (runIncludedSourceConcepts) {
    # Included concepts ------------------------------------------------------------------
    ParallelLogger::logInfo("Fetching included source concepts - Started at ", Sys.time())
    if (nrow(subsetIncluded) > 0) {
      start <- Sys.time()
      ParallelLogger::logInfo("Counting codes in concept sets")
      if (useExternalConceptCountsTable) {
        sql <-
          SqlRender::loadRenderTranslateSql(
            "CohortSourceConceptsFromCcTable.sql",
            packageName = "CohortDiagnostics",
            dbms = connection@dbms,
            oracleTempSchema = oracleTempSchema,
            cdm_database_schema = cdmDatabaseSchema,
            concept_counts_database_schema = conceptCountsDatabaseSchema,
            concept_counts_table = conceptCountsTable,
            concept_counts_table_is_temp = conceptCountsTableIsTemp
          )
        sourceCounts <-
          DatabaseConnector::querySql(connection, sql, snakeCaseToCamelCase = TRUE)
        
        sql <-
          SqlRender::loadRenderTranslateSql(
            "CohortStandardConceptsFromCcTable.sql",
            packageName = "CohortDiagnostics",
            dbms = connection@dbms,
            oracleTempSchema = oracleTempSchema,
            cdm_database_schema = cdmDatabaseSchema,
            concept_counts_database_schema = conceptCountsDatabaseSchema,
            concept_counts_table = conceptCountsTable,
            concept_counts_table_is_temp = conceptCountsTableIsTemp
          )
        standardCounts <-
          DatabaseConnector::querySql(connection, sql, snakeCaseToCamelCase = TRUE)
        
        # To avoid double counting, subtract standard concept counts included in source counts.
        # Note: this can create negative counts, because a source concept can be double counted itself
        # if it maps to more than one standard concept, but it will show correctly in the viewer app,
        # where the counts will be added back in.
        dupCounts <-
          aggregate(conceptCount ~ conceptId, sourceCounts, sum)
        colnames(dupCounts)[2] <- "dupCount"
        dupSubjects <-
          aggregate(conceptSubjects ~ conceptId, sourceCounts, sum)
        colnames(dupSubjects)[2] <- "dupSubjects"
        standardCounts <-
          merge(standardCounts, dupCounts, all.x = TRUE)
        standardCounts <-
          merge(standardCounts, dupSubjects, all.x = TRUE)
        standardCounts$dupCount[is.na(standardCounts$dupCount)] <- 0
        standardCounts$dupSubjects[is.na(standardCounts$dupSubjects)] <-
          0
        standardCounts$conceptCount <-
          standardCounts$conceptCount - standardCounts$dupCount
        standardCounts$conceptSubjects <-
          standardCounts$conceptSubjects - standardCounts$dupSubjects
        standardCounts$dupCount <- NULL
        standardCounts$dupSubjects <- NULL
        
        counts <- dplyr::bind_rows(sourceCounts, standardCounts)
      } else {
        sql <- SqlRender::loadRenderTranslateSql(
          "CohortSourceCodes.sql",
          packageName = "CohortDiagnostics",
          dbms = connection@dbms,
          oracleTempSchema = oracleTempSchema,
          cdm_database_schema = cdmDatabaseSchema,
          by_month = FALSE,
          use_source_values = FALSE
        )
        counts <-
          DatabaseConnector::querySql(connection, sql, snakeCaseToCamelCase = TRUE)
      }
      
      colnames(counts)[colnames(counts) == "conceptSetId"] <-
        "uniqueConceptSetId"
      counts <-
        merge(conceptSets[, c("cohortId",
                              "conceptSetId",
                              "conceptSetName",
                              "uniqueConceptSetId")], counts)
      counts$uniqueConceptSetId <- NULL
      counts <- counts[order(
        counts$cohortId,
        counts$conceptSetId,
        counts$conceptId,
        counts$sourceConceptName,	
        counts$sourceVocabularyId
      ),]
      counts <-
        counts[counts$cohortId %in% subsetIncluded$cohortId,]
      if (nrow(counts) > 0) {
        counts$databaseId <- databaseId
        counts <-
          enforceMinCellValue(counts, "conceptSubjects", minCellCount)
        counts <-
          enforceMinCellValue(counts, "conceptCount", minCellCount)
      }
      writeToCsv(
        counts,
        file.path(exportFolder, "included_source_concept.csv"),
        incremental = incremental,
        cohortId = subsetIncluded$cohortId
      )
      recordTasksDone(
        cohortId = subsetIncluded$cohortId,
        task = "runIncludedSourceConcepts",
        checksum = subsetIncluded$checksum,
        recordKeepingFile = recordKeepingFile,
        incremental = incremental
      )
      delta <- Sys.time() - start
      ParallelLogger::logInfo(paste(
        "Finding source codes took",
        signif(delta, 3),
        attr(delta, "units")
      ))
    }
  }
  
  if (runOrphanConcepts) {
    # Orphan concepts ---------------------------------------------------------
    ParallelLogger::logInfo("Finding orphan concepts - started at ", Sys.time())
    if (nrow(subsetOrphans > 0)) {
      start <- Sys.time()
      if (!useExternalConceptCountsTable) {
        createConceptCountsTable(
          connection = connection,
          cdmDatabaseSchema = cdmDatabaseSchema,
          oracleTempSchema = oracleTempSchema,
          conceptCountsDatabaseSchema = conceptCountsDatabaseSchema,
          conceptCountsTable = conceptCountsTable,
          conceptCountsTableIsTemp = conceptCountsTableIsTemp
        )
      }
      runOrphanConcepts <- function(conceptSet) {
        ParallelLogger::logInfo("- Finding orphan concepts for concept set ",
                                conceptSet$conceptSetName)
        orphanConcepts <-
          .findOrphanConcepts(
            connection = connection,
            cdmDatabaseSchema = cdmDatabaseSchema,
            oracleTempSchema = oracleTempSchema,
            useCodesetTable = TRUE,
            codesetId = conceptSet$uniqueConceptSetId,
            conceptCountsDatabaseSchema = conceptCountsDatabaseSchema,
            conceptCountsTable = conceptCountsTable,
            conceptCountsTableIsTemp = conceptCountsTableIsTemp
          )
        orphanConcepts$uniqueConceptSetId <-
          rep(conceptSet$uniqueConceptSetId, nrow(orphanConcepts))
        return(orphanConcepts)
      }
      
      data <-
        lapply(
          split(
            uniqueConceptSets,
            uniqueConceptSets$uniqueConceptSetId
          ),
          runOrphanConcepts
        )
      data <- do.call(rbind, data)
      data <-
        merge(conceptSets[, c("cohortId",
                              "conceptSetId",
                              "conceptSetName",
                              "uniqueConceptSetId")], data)
      data$uniqueConceptSetId <- NULL
      data$conceptName <- NULL
      data$databaseId <- rep(databaseId, nrow(data))
      data <- data[data$cohortId %in% subsetOrphans$cohortId,]
      if (nrow(data) > 0) {
        data <- enforceMinCellValue(data, "conceptCount", minCellCount)
      }
      writeToCsv(
        data,
        file.path(exportFolder, "orphan_concept.csv"),
        incremental = incremental,
        cohortId = subsetOrphans$cohortId
      )
      recordTasksDone(
        cohortId = subsetOrphans$cohortId,
        task = "runOrphanConcepts",
        checksum = subsetOrphans$checksum,
        recordKeepingFile = recordKeepingFile,
        incremental = incremental
      )
      
      if (!useExternalConceptCountsTable) {
        ParallelLogger::logTrace("Dropping temp concept counts")
        sql <-
          "TRUNCATE TABLE #concept_counts; DROP TABLE #concept_counts;"
        DatabaseConnector::renderTranslateExecuteSql(connection,
                                                     sql,
                                                     progressBar = FALSE,
                                                     reportOverallTime = FALSE)
      }
      delta <- Sys.time() - start
      ParallelLogger::logInfo(paste(
        "Finding orphan concepts took",
        signif(delta, 3),
        attr(delta, "units")
      ))
    }
  }
  ParallelLogger::logTrace("Dropping temp concept set tables")
  sql <- "TRUNCATE TABLE #Codesets; DROP TABLE #Codesets;"
  DatabaseConnector::renderTranslateExecuteSql(
    connection,
    sql,
    oracleTempSchema = oracleTempSchema,
    progressBar = FALSE,
    reportOverallTime = FALSE
  )
  
  delta <- Sys.time() - startConceptSetDiagnostics
  ParallelLogger::logInfo(paste(
    "Running concept set diagnostics",
    signif(delta, 3),
    attr(delta, "units")
  ))
}
