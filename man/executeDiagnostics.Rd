% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/executeDiagnostics.R
\name{executeDiagnostics}
\alias{executeDiagnostics}
\title{Execute cohort diagnostics}
\usage{
executeDiagnostics(
  cohortDefinitionSet,
  exportFolder,
  databaseId,
  cohortDatabaseSchema,
  databaseName = NULL,
  databaseDescription = NULL,
  connectionDetails = NULL,
  connection = NULL,
  cdmDatabaseSchema,
  tempEmulationSchema = getOption("sqlRenderTempEmulationSchema"),
  cohortTable = "cohort",
  cohortTableNames = CohortGenerator::getCohortTableNames(cohortTable = cohortTable),
  vocabularyDatabaseSchema = cdmDatabaseSchema,
  cohortIds = NULL,
  cdmVersion = 5,
  runInclusionStatistics = TRUE,
  runIncludedSourceConcepts = TRUE,
  runOrphanConcepts = TRUE,
  runTimeSeries = FALSE,
  runVisitContext = TRUE,
  runBreakdownIndexEvents = TRUE,
  runIncidenceRate = TRUE,
  runCohortRelationship = TRUE,
  runTemporalCohortCharacterization = TRUE,
  temporalCovariateSettings = getDefaultCovariateSettings(),
  minCellCount = 5,
  minCharacterizationMean = 0.01,
  irWashoutPeriod = 0,
  incremental = FALSE,
  incrementalFolder = exportFolder,
  conceptCountsTable = "concept_counts",
  runFeatureExtractionOnSample = FALSE,
  sampleN = 1000,
  seed = 64374,
  seedArgs = NULL
)
}
\arguments{
\item{cohortDefinitionSet}{A data.frame with cohort definitions created by 
`CohortGenerator::getCohortDefinitionSet` that must include 
the columns cohortId, cohortName, json, sql.}

\item{exportFolder}{The folder where the results will be exported to}

\item{databaseId}{A short string for identifying the database (e.g. 'Synpuf').}

\item{cohortDatabaseSchema}{Schema name where your cohort table resides. Note that for SQL Server,
this should include both the database and schema name, for example
'scratch.dbo'.}

\item{databaseName}{The full name of the database. If NULL, defaults to value in cdm_source table.}

\item{databaseDescription}{A short description (several sentences) of the database. If NULL, defaults to value in cdm_source table.}

\item{connectionDetails}{An object of type \code{connectionDetails} as created using the
\code{\link[DatabaseConnector]{createConnectionDetails}} function in the
DatabaseConnector package. Can be left NULL if \code{connection} is
provided.}

\item{connection}{An object of type \code{connection} as created using the
\code{\link[DatabaseConnector]{connect}} function in the
DatabaseConnector package. Can be left NULL if \code{connectionDetails}
is provided, in which case a new connection will be opened at the start
of the function, and closed when the function finishes.}

\item{cdmDatabaseSchema}{Schema name where your patient-level data in OMOP CDM format resides.
Note that for SQL Server, this should include both the database and
schema name, for example 'cdm_data.dbo'.}

\item{tempEmulationSchema}{Some database platforms like Oracle and Impala do not truly support temp tables. To emulate temp 
tables, provide a schema with write privileges where temp tables can be created.}

\item{cohortTable}{Name of the cohort table.}

\item{cohortTableNames}{Cohort Table names used by CohortGenerator package.}

\item{vocabularyDatabaseSchema}{Schema name where your OMOP vocabulary data resides. This is 
commonly the same as cdmDatabaseSchema. Note that for 
SQL Server, this should include both the database and
schema name, for example 'vocabulary.dbo'.}

\item{cohortIds}{A vector of one or more Cohort Ids.}

\item{cdmVersion}{The version of the OMOP CDM. Default 5. (Note: only 5 is supported.)}

\item{runInclusionStatistics}{Generate and export statistic on the cohort inclusion rules?}

\item{runIncludedSourceConcepts}{Generate and export the source concepts included in the cohorts?}

\item{runOrphanConcepts}{Generate and export potential orphan concepts?}

\item{runTimeSeries}{Generate and export the time series diagnostics?}

\item{runVisitContext}{Generate and export index-date visit context?}

\item{runBreakdownIndexEvents}{Generate and export the breakdown of index events?}

\item{runIncidenceRate}{Generate and export the cohort incidence  rates?}

\item{runCohortRelationship}{Generate and export the cohort relationship? Cohort relationship checks the temporal
relationship between two or more cohorts.}

\item{runTemporalCohortCharacterization}{Generate and export the temporal cohort characterization?
Only records with values greater than 0.001 are returned.}

\item{temporalCovariateSettings}{Either an object of type \code{covariateSettings} as created using one of
the createTemporalCovariateSettings function in the FeatureExtraction package, or a list
of such objects.}

\item{minCellCount}{The minimum cell count for fields contains person counts or fractions}

\item{minCharacterizationMean}{The minimum mean value for characterization output. Values below this will be cut off from output. This
will help reduce the file size of the characterization output, but will remove information
on covariates that have very low values. The default is 0.001 (i.e. 0.1 percent)}

\item{irWashoutPeriod}{Number of days washout to include in calculation of incidence rates - default is 0}

\item{incremental}{`TRUE` or `FALSE` (default). If TRUE diagnostics for cohorts in the 
cohort definition set that have not changed will be skipped and existing results 
csv files will be updated. If FALSE then diagnostics for all cohorts in the cohort 
definition set will be executed and pre-existing results files will be deleted.}

\item{incrementalFolder}{If \code{incremental = TRUE}, specify a folder where records are kept
of which cohort diagnostics has been executed.}

\item{conceptCountsTable}{Concepts count table name. The default is "#concept_counts" to create a temporal concept counts table.
If an external concept counts table is used, provide the name in character, e.g. "concept_counts" without a hash.}

\item{runFeatureExtractionOnSample}{Logical. If TRUE, the function will operate on a sample of the data.
Default is FALSE, meaning the function will operate on the full data set.}

\item{sampleN}{Integer. The number of records to include in the sample if runFeatureExtractionOnSample is TRUE.
Default is 1000. Ignored if runFeatureExtractionOnSample is FALSE.}

\item{seed}{Integer. The seed for the random number generator used to create the sample.
This ensures that the same sample can be drawn again in future runs. Default is 64374.}

\item{seedArgs}{List. Additional arguments to pass to the sampling function.
This can be used to control aspects of the sampling process beyond the seed and sample size.}
}
\description{
Runs the cohort diagnostics on all (or a subset of) the cohorts.
Assumes the cohorts have already been instantiated with the CohortGenerator package.

Characterization:
If runTemporalCohortCharacterization argument is TRUE, then the following default covariateSettings object will be created
using \code{RFeatureExtraction::createTemporalCovariateSettings}
Alternatively, a covariate setting object may be created using the above as an example.
}
\details{
The \code{cohortDefinitionSet} argument must be a data frame with at least the following columns.
It is created by \code{CohortGenerator::getCohortDefinitionSet()}
These fields will be exported as is to the cohort table that is part of Cohort Diagnostics results data model. 
Any additional fields found will be stored as JSON object in the metadata field of the cohort table:
\describe{
\item{cohortId}{The cohort Id is the id used to identify  a cohort definition. This is required to be unique. It will be used to create file names.}
\item{cohortName}{The full name of the cohort. This will be shown in the Shiny app.}
\item{json}{The JSON cohort definition for the cohort.}
\item{sql}{The SQL of the cohort definition rendered from the cohort json.}
}
}
\examples{
\dontrun{
# Load cohorts (assumes that they have already been instantiated)
cohortTableNames <- CohortGenerator::getCohortTableNames(cohortTable = "cohort")
cohorts <- CohortGenerator::getCohortDefinitionSet(packageName = "MyGreatPackage")
connectionDetails <- createConnectionDetails(
  dbms = "postgresql",
  server = "ohdsi.com",
  port = 5432,
  user = "me",
  password = "secure"
)

executeDiagnostics(
  cohorts = cohorts,
  exportFolder = "export",
  cohortTableNames = cohortTableNames,
  cohortDatabaseSchema = "results",
  cdmDatabaseSchema = "cdm",
  databaseId = "mySpecialCdm",
  connectionDetails = connectionDetails
)

# Use a custom set of cohorts defined in a data.frame
cohorts <- data.frame(
  cohortId = c(100),
  cohortName = c("Cohort Name"),
  logicDescription = c("My Cohort"),
  sql = c(readLines("path_to.sql")),
  json = c(readLines("path_to.json"))
)
executeDiagnostics(
  cohorts = cohorts,
  exportFolder = "export",
  cohortTable = "cohort",
  cohortDatabaseSchema = "results",
  cdmDatabaseSchema = "cdm",
  databaseId = "mySpecialCdm",
  connectionDetails = connectionDetails
)
}

}
